{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc4516d",
   "metadata": {
    "editable": false,
    "id": "1769174f",
    "lang": "fr",
    "tags": [
     "problem-title"
    ]
   },
   "source": [
    "# Devoir 3, Question 1 : Algorithme de rétropropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57114b7",
   "metadata": {
    "editable": false,
    "id": "52972702",
    "lang": "en",
    "tags": [
     "problem-title"
    ]
   },
   "source": [
    "# Homework 3, Question 1: Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ca069",
   "metadata": {
    "editable": false,
    "id": "930c12a4",
    "lang": "fr",
    "tags": [
     "problem-statement"
    ]
   },
   "source": [
    "Soit la fonction d’activation de neurone tangente hyperbolique, définie par l’équation suivante :\n",
    "$$p(z)=\\tanh(z)=\\frac{\\exp(z) − \\exp(−z)}{\\exp(z) + \\exp(−z)}=\\frac{\\exp(2z) − 1}{\\exp(2z) + 1}.$$\n",
    "\n",
    "Développez les équations pour mettre à jour les poids et biais d’un perceptron multicouche avec des neurones utilisant cette fonction d’activation. N'oubliez pas les équations pour mettre à jour la couche de sortie ainsi que les équations pour mettre à jour les couches cachées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb32494",
   "metadata": {
    "editable": false,
    "id": "6daf7357",
    "lang": "en",
    "tags": [
     "problem-statement"
    ]
   },
   "source": [
    "Consider the hyperbolic tangent neuron activation function, defined by the following equation:\n",
    "$$p(z)=\\tanh(z)=\\frac{\\exp(z) − \\exp(−z)}{\\exp(z) + \\exp(−z)}=\\frac{\\exp(2z) − 1}{\\exp(2z) + 1}.$$\n",
    "\n",
    "Expand the equations to update the weights and biases of a multilayer perceptron with neurons using this activation function. Don't forget the equations to update the output layer as well as the equations to update the hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841a9ea0",
   "metadata": {
    "editable": false,
    "id": "2f313c44",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Entrez votre solution à Q1 dans la cellule ci-dessous (markdown et $\\LaTeX$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01265c00",
   "metadata": {
    "editable": false,
    "id": "8a20a18f",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Enter your answer to Q1 in the cell below (markdown and $\\LaTeX$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633455b6",
   "metadata": {
    "editable": false,
    "tags": [
     "feedback"
    ]
   },
   "source": [
    "\n",
    "        <div class=\"feedback-cell\" style=\"background: rgba(100 , 100 , 100 , 0.4)\">\n",
    "            <h3>Votre soumission a été enregistrée!</h3>\n",
    "            <ul>\n",
    "                <li>notez qu'il n'y a <strong>pas</strong> de correction automatique pour cet exercice&puncsp;;</li>\n",
    "                <li>par conséquent, votre note est <strong>actuellement</strong> zéro&puncsp;;</li>\n",
    "                <li>elle sera cependant ajustée par le professeur dès que la correction manuelle sera complétée&puncsp;;</li>\n",
    "                <li>vous pouvez soumettre autant de fois que nécessaire jusqu'à la date d'échéance&puncsp;;</li>\n",
    "                <li>mais évitez de soumettre inutilement.</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c26814f",
   "metadata": {
    "deletable": false,
    "id": "38b5c8b6",
    "tags": [
     "user-answer-D3Q1",
     "editable"
    ]
   },
   "source": [
    "Soit le jeu de données: \\\n",
    "$\\mathcal{X} = \\{\\mathrm{x}^t,\\mathrm{r}^t\\}_{t=1}^N$ \n",
    "où $\\mathbf{r}^t = [\\mathrm{r}_1^t \\mathrm{r}_1^t ... \\mathrm{r}_K^t]$, \n",
    "avec \n",
    "$\\mathrm{r}_j^t = \n",
    "\\begin{equation*}\n",
    "  \\left\\{\n",
    "    \\begin{aligned}\n",
    "      & 1 \\textrm{ si } \\mathrm{x}^t \\in \\mathrm{C}_j \\\\\n",
    "      & 0 \\textrm{ autrement }\n",
    "    \\end{aligned}\n",
    "  \\right.\n",
    "\\end{equation*}$\n",
    "\n",
    "On définit l'erreur sur l'ensemble du jeu de données $\\mathcal{X}$ par: \\\n",
    "$\\mathrm{E} = \\frac{1}{N}\\sum_{t=1}^N\\mathrm{E^t}$\n",
    "\n",
    "\\* Mise à jour des poids et du biais sur la couche de sortie: \\\n",
    "$\\Delta\\mathrm{w}_{j,i} = -\\eta\\frac{\\partial\\mathrm{E}}{\\partial\\mathrm{w}_{j,i}} = -\\frac{\\eta}{\\mathrm{N}}\\sum_{t=1}^N\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{w}_{j,i}}$ \\\n",
    "$\\Delta\\mathrm{w}_{j,0} = -\\eta\\frac{\\partial\\mathrm{E}}{\\partial\\mathrm{w}_{j,0}} = -\\frac{\\eta}{\\mathrm{N}}\\sum_{t=1}^N\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{w}_{j,0}}$ \n",
    "\n",
    "Grâce à la règle de chaînage, on peut écrire: \\\n",
    "$\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{w}_{j,i}} = \n",
    "\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{e}_{j}^t} \n",
    "\\frac{\\partial\\mathrm{e}_{j}^t}{\\partial\\mathrm{y}_{j}^t} \n",
    "\\frac{\\partial\\mathrm{y}_{j}^t}{\\partial\\mathrm{a}_{j}^t} \n",
    "\\frac{\\partial\\mathrm{a}_{j}^t}{\\partial\\mathrm{w}_{j,i}}$\n",
    "\n",
    "$\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{e}_{j}^t} = \n",
    "\\frac{\\partial}{\\partial\\mathrm{e}_{j}^t}\\frac{1}{2}\\sum_{l=1}^N(\\mathrm{e}_l^t)^2 = \\mathrm{e}_j^t$\n",
    "\n",
    "$\\frac{\\partial\\mathrm{e}_{j}^t}{\\partial\\mathrm{y}_{j}^t} = \n",
    "\\frac{\\partial}{\\partial\\mathrm{y}_{j}^t}(\\mathrm{r}_j^t - \\mathrm{y}_j^t) = -1$\n",
    "\n",
    "$\\begin{align*}\n",
    "\\frac{\\partial\\mathrm{y}_{j}^t}{\\partial\\mathrm{a}_{j}^t} \n",
    "&= \\frac{\\partial}{\\partial\\mathrm{a}_{j}^t}\\tanh(\\mathrm{a}_j^t) \\\\\n",
    "&= \\frac{\\partial}{\\partial\\mathrm{a}_{j}^t}\\frac{\\exp(\\mathrm{a}_j^t) - \\exp(-\\mathrm{a}_j^t)}{\\exp(\\mathrm{a}_j^t) + \\exp(-\\mathrm{a}_j^t)} \\\\\n",
    "&= \\frac{\\big(\\exp(\\mathrm{a}_j^t) + \\exp(-\\mathrm{a}_j^t)\\big)^2 - \\big(\\exp(\\mathrm{a}_j^t) - \\exp(-\\mathrm{a}_j^t)\\big)^2}{\\Big(\\exp(\\mathrm{a}_j^t) + \\exp(-\\mathrm{a}_j^t)\\Big)^2} \\\\\n",
    "&= 1 - \\big(\\frac{\\exp(\\mathrm{a}_j^t) - \\exp(-\\mathrm{a}_j^t)}{\\exp(\\mathrm{a}_j^t) + \\exp(-\\mathrm{a}_j^t)}\\big)^2 \\\\\n",
    "&= 1 - (\\tanh(\\mathrm{a}_j^t))^2 = 1 - (\\mathrm{y}_j^t)^2\n",
    "\\end{align*}$\n",
    "\n",
    "$\\frac{\\partial\\mathrm{a}_{j}^t}{\\partial\\mathrm{w}_{j,i}} = \\frac{\\partial}{\\partial\\mathrm{w}_{j,i}}\\big(\\sum_{l=1}^K\\mathrm{w}_{j,l}\\mathrm{y}_l^t + \\mathrm{w}_{j,0}\\big) = \\mathrm{y}_i^t$\n",
    "\n",
    "$\\frac{\\partial\\mathrm{a}_{j}^t}{\\partial\\mathrm{w}_{j,0}} = \\frac{\\partial}{\\partial\\mathrm{w}_{j,0}}\\big(\\sum_{l=1}^K\\mathrm{w}_{j,l}\\mathrm{y}_l^t + \\mathrm{w}_{j,0}\\big) = 1$\n",
    "\n",
    "On a donc: \\\n",
    "$\\Delta\\mathrm{w}_{j,i} = \\frac{\\eta}{\\mathrm{N}}\\sum_{t=1}^N \\mathrm{e}_j^t \\big(1 - (\\mathrm{y}_j^t)^2\\big) \\mathrm{y}_i^t$ \\\n",
    "$\\Delta\\mathrm{w}_{j,0} = \\frac{\\eta}{\\mathrm{N}}\\sum_{t=1}^N \\mathrm{e}_j^t \\big(1 - (\\mathrm{y}_j^t)^2\\big)$\n",
    "\n",
    "\n",
    "\\* Mise à jour des poids et du biais sur les couches cachées: \\\n",
    "Posons $\\delta_j^t = \\mathrm{e}_j^t \\big(1 - (\\mathrm{y}_j^t)^2\\big)$\n",
    "\n",
    "$\\Delta\\mathrm{w}_{j,i} = \\frac{\\eta}{\\mathrm{N}}\\sum_{t=1}^N \\delta_j^t \\mathrm{y}_i^t$ \\\n",
    "$\\Delta\\mathrm{w}_{j,0} = \\frac{\\eta}{\\mathrm{N}}\\sum_{t=1}^N \\delta_j^t$\n",
    "\n",
    "$\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{w}_{j,i}} = \n",
    "\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{y}_{j}^t} \n",
    "\\frac{\\partial\\mathrm{y}_{j}^t}{\\partial\\mathrm{a}_{j}^t} \n",
    "\\frac{\\partial\\mathrm{a}_{j}^t}{\\partial\\mathrm{w}_{j,i}}$\n",
    "\n",
    "$\\mathrm{E}^t = \\frac{1}{2}\\sum_{k}(\\mathrm{e}_k^t)^2, \\mathrm{e_k}\\textrm{ est l'erreur sur la couche suivante }$ \n",
    "\n",
    "$\\begin{align*}\n",
    "\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{y}_j^t} \n",
    "&= \\frac{\\partial}{\\partial\\mathrm{y}_j^t}\\frac{1}{2}\\sum_{k}(\\mathrm{e}_k^t)^2\n",
    "= \\sum_{k}\\mathrm{e}_k^t \\frac{\\partial\\mathrm{e}_k^t}{\\partial\\mathrm{y}_j^t} \\\\\n",
    "&= \\sum_{k}\\mathrm{e}_k^t \\frac{\\partial\\mathrm{e}_k^t}{\\partial\\mathrm{a}_k^t} \\frac{\\partial\\mathrm{a}_k^t}{\\partial\\mathrm{y}_j^t} \\\\\n",
    "&= \\sum_{k}\\mathrm{e}_k^t \\frac{\\partial(\\mathrm{r}_k^t - \\mathrm{y}_k^t)}{\\partial\\mathrm{a}_k^t} \\frac{\\partial(\\sum_{l}\\mathrm{w}_{k,l}\\mathrm{y}_l^t + \\mathrm{w}_{k,0})}{\\partial\\mathrm{y}_j^t} \\\\\n",
    "&= -\\sum_{k}\\mathrm{e}_k^t \\big(1 - (\\mathrm{y}_j^t)^2\\big) \\mathrm{w}_{k,j}\n",
    "\\end{align*}$\n",
    "\n",
    "Posons: $\\delta_k^t = \\mathrm{e}_k^t \\big(1 - (\\mathrm{y}_j^t)^2\\big)$ \\\n",
    "$\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{y}_j^t} = -\\sum_{k} \\delta_k^t \\mathrm{w}_{k,j}$\n",
    "\n",
    "$\\frac{\\partial\\mathrm{E}^t}{\\partial\\mathrm{w}_{j,i}} = \n",
    "\\bigg[-\\sum_{k} \\delta_k^t \\mathrm{w}_{k,j}\\bigg] \\big(1 - (\\mathrm{y}_j^t)^2\\big) \\mathrm{y}_i^t$\n",
    "\n",
    "Posons: $\\delta_j^t = \\big(1 - (\\mathrm{y}_j^t)^2\\big)\\sum_{k} \\delta_k^t \\mathrm{w}_{k,j}$\n",
    "\n",
    "$\\Delta\\mathrm{w}_{j,i} = \\frac{\\eta}{\\mathrm{N}}\\sum_{t=1}^N \\delta_j^t \\mathrm{y}_i^t$ \\\n",
    "$\\Delta\\mathrm{w}_{j,0} = \\frac{\\eta}{\\mathrm{N}}\\sum_{t=1}^N \\delta_j^t$"
   ]
  }
 ],
 "metadata": {
  "PAX": {
   "userLang": "fr"
  },
  "celltoolbar": "",
  "jupytext": {
   "notebook_metadata_filter": "celltoolbar",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.3",
    "jupytext_version": "1.11.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (PAX)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
